---
title: "Golang Pokemon Clawler"
date: "2021-04-04"
author: kaichi
---

## å‰è¨€

æœ€è¿‘æƒ³å¼„ç‚¹æ•°æ®æ¥ç»ƒæ‰‹ï¼Œé‚å°±æƒ³åˆ°ä»ç½‘ä¸Šçˆ¬ç‚¹å„¿ pokemon çš„ä¿¡æ¯ã€‚åˆšå¥½æœ€è¿‘å­¦ goï¼Œäºæ˜¯å°±æƒ³ç”¨ go æ¥å®ç°ï¼Œéšä¾¿æ¨è [go è¯­è¨€åœ£ç»](https://books.studygolang.com/gopl-zh/) è¿™æœ¬ä¹¦ã€‚è¿™æ˜¯æˆ‘ç¬¬ä¸€ä¸ªçˆ¬ ğŸ› é¡¹ç›®ï¼Œå®ç°çš„ä¹Ÿå¾ˆç®€å•ã€‚æº [wiki.52poke.com](https://wiki.52poke.com/wiki/%E5%AE%9D%E5%8F%AF%E6%A2%A6%E5%88%97%E8%A1%A8%EF%BC%88%E6%8C%89%E5%85%A8%E5%9B%BD%E5%9B%BE%E9%89%B4%E7%BC%96%E5%8F%B7%EF%BC%89/%E7%AE%80%E5%8D%95%E7%89%88)ï¼Œ è§£æ html ç”¨åˆ° [htmlquery](https://pkg.go.dev/github.com/antchfx/htmlquery@v1.2.3), [htmlquery](https://pkg.go.dev/github.com/antchfx/htmlquery@v1.2.3) ä½¿ç”¨çš„æ˜¯[xpath é€‰æ‹©å™¨](https://www.w3school.com.cn/xpath/xpath_syntax.asp)ã€‚

github: [é¡¹ç›®æºç ](https://github.com/kaichii/pokemon-clawler)

## [htmlquery](https://pkg.go.dev/github.com/antchfx/htmlquery@v1.2.3) åŸºæœ¬ç”¨æ³•

### å¸¸ç”¨æ–¹æ³•

#### LoadURL

```go
// æ ¹æ®ç»™å®šçš„ url è¿”å›è¯¥ url çš„ HTML document
func LoadURL(url string) (*html.Node, error)
```

#### Find

```go
// è¿”å› top èŠ‚ç‚¹ä¸‹æ‰€æœ‰æ»¡è¶³ `expr` çš„æ‰€æœ‰èŠ‚ç‚¹
func Find(top *html.Node, expr string) []*html.Node
```

#### FindOne

```go
// è¿”å› top èŠ‚ç‚¹ä¸‹æ»¡è¶³ `expr` çš„ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
func FindOne(top *html.Node, expr string) *html.Node
```

#### InnerText

```go
// è¿”å›èŠ‚ç‚¹ tag é—´çš„æ–‡æœ¬
func InnerText(n *html.Node) string
```

#### SelectAttr

```go
// è¿”å› n èŠ‚ç‚¹ä¸Šå±æ€§åä¸º name çš„å±æ€§å€¼
func SelectAttr(n *html.Node, name string) (val string)
```

## çˆ¬å–æ•°æ®

### ç”Ÿæˆè¦çˆ¬å–çš„ç½‘é¡µé“¾æ¥

æ ¹æ®ç»™å®šçš„ä¸»é¡µé“¾æ¥ï¼Œè·å–éœ€è¦è·å–çš„ pokemon çš„ä¸»é¡µé“¾æ¥ï¼Œç„¶åä¸¢åˆ° channel é‡Œï¼Œç­‰å¾…åç»­çš„å¤„ç†ã€‚

```go
func generateUrls(url string, out chan<- string) {
	doc, err := htmlquery.LoadURL(url)

	utils.CheckError(err, "[load url]:")

	nodes, err := htmlquery.QueryAll(doc, "//table[@class=\"a-c roundy eplist bgl-ç¥å¥‡å®è´ç™¾ç§‘ b-ç¥å¥‡å®è´ç™¾ç§‘ bw-2\"]/tbody/tr/td[last()]/a[@class=\"mw-redirect\"]")

	utils.CheckError(err, "[query //tr/td[last()]/a[@class=\"mw-redirect\"]]:")

	for _, a := range nodes {
		out <- fmt.Sprintf("%s%s", baseUrl, htmlquery.SelectAttr(a, "href"))
	}

	close(out)
}

```

### æå–æ•°æ®

æå–é“¾æ¥çš„ HTML æ–‡æœ¬é‡Œæˆ‘ä»¬æƒ³è¦è·å–çš„æ•°æ®ï¼Œ ä¸»è¦å°±æ˜¯åˆ†æ HTML æ–‡æ¡£ç»“æ„ï¼Œå†™å‡ºå®šä½åˆ°æˆ‘ä»¬éœ€è¦å…¶æ•°æ®çš„æ–‡æ¡£èŠ‚ç‚¹çš„ xpath è¡¨è¾¾å¼ï¼Œæå–æ•°æ®å°±å®Œäº‹äº†ã€‚

å¤„ç† channel in é‡Œé“¾æ¥ï¼Œ å¹¶ä»ä¸­æå–æ•°æ®ä¸¢åˆ° channel out é‡Œã€‚

```go
func parse(in <-chan string, out chan<- []string) {
	for url := range in {

		log.Println(url)

		name := strings.TrimLeft(url, baseUrl+"/wiki/")

		doc, err := htmlquery.LoadURL(url)

		utils.CheckError(err, "[load url]:")

		root := htmlquery.FindOne(doc, "//div[@class=\"mw-parser-output\"]/table[2]/tbody")

		result := []string{}

		order := ""

		chineseName := ""

		imageUri := ""

		description := ""

		orderNode := htmlquery.FindOne(root, "//a[@title=\"å®å¯æ¢¦åˆ—è¡¨ï¼ˆæŒ‰å…¨å›½å›¾é‰´ç¼–å·ï¼‰\"]")

		chineseNameNode := htmlquery.FindOne(root, "//td/span[@style=\"font-size:1.5em\"]/b")

		imageNode := htmlquery.FindOne(root, "/tr[2]//a[@class=\"image\"]/img")

		descriptionNode := htmlquery.FindOne(doc, "//div[@class=\"mw-parser-output\"]/p[2]")

		if chineseNameNode != nil {
			chineseName = htmlquery.InnerText(chineseNameNode)
		}

		if imageNode != nil {
			imageUri = "https:" + htmlquery.SelectAttr(imageNode, "data-url")
		}

		if descriptionNode != nil {
			description = strings.Replace(htmlquery.InnerText(descriptionNode), "\n", "", -1)
		}

		if orderNode != nil {
			order = htmlquery.InnerText(orderNode)
		}

		result = append(result, order, name, chineseName, imageUri, description)

		out <- result
	}

	close(out)
}
```

### å¯¼å‡ºæ•°æ®

```go
func main() {

	result, err := os.Create("pokemon.csv")

	utils.CheckError(err, "[creat file]:")

	defer result.Close()

	result.WriteString("\xEF\xBB\xBF")

	writer := csv.NewWriter(result)

	urls := make(chan string)
	columns := make(chan []string)

	go generateUrls(fmt.Sprintf("%s/wiki/%s", baseUrl, string("å®å¯æ¢¦åˆ—è¡¨ï¼ˆæŒ‰å…¨å›½å›¾é‰´ç¼–å·ï¼‰/ç®€å•ç‰ˆ")), urls)

	go parse(urls, columns)

	for c := range columns {
		err := writer.Write(c)

		utils.CheckError(err, "[write line]:")
	}

	writer.Flush()
}
```
